# Kafka Toolkit Lib

Biblioteca Go para integraÃ§Ã£o robusta, tipada e flexÃ­vel com Apache Kafka, suportando serializaÃ§Ã£o Avro, JSON e Protobuf, alÃ©m de integraÃ§Ã£o com Schema Registry. Focada em produtividade, seguranÃ§a e performance, abstrai detalhes de configuraÃ§Ã£o e oferece APIs simples para publicaÃ§Ã£o e consumo de mensagens.

## Principais Recursos
- **PublicaÃ§Ã£o e consumo fortemente tipados** (genÃ©ricos)
- **SerializaÃ§Ã£o/DeserializaÃ§Ã£o**: Avro, JSON, Protobuf
- **IntegraÃ§Ã£o transparente com Schema Registry**
- **ConfiguraÃ§Ã£o via variÃ¡veis de ambiente** (usando Viper)
- **Gerenciamento de prioridades de performance e consistÃªncia** para producers e consumers
- **Thread-safe e singleton** para publishers e consumers

## InstalaÃ§Ã£o

Adicione ao seu projeto Go:
```sh
go get github.com/Dieg657/kafka-toolkit-lib
```

## ConfiguraÃ§Ã£o

A biblioteca utiliza variÃ¡veis de ambiente para configuraÃ§Ã£o. Veja abaixo o detalhamento de cada uma:

| VariÃ¡vel                           | DescriÃ§Ã£o                                                    | Valores PossÃ­veis / Exemplo                | Default                | ObrigatÃ³rio? | Comportamento se ausente |
|------------------------------------|--------------------------------------------------------------|--------------------------------------------|------------------------|--------------|-------------------------|
| **KAFKA_BROKERS**                  | Lista de brokers Kafka (endpoints)                           | host1:9092,host2:9092                      | â€”                      | Sim          | erro                    |
| **KAFKA_GROUPID**                  | Identificador do grupo de consumidores                       | string                                     | â€”                      | Sim          | erro                    |
| **KAFKA_USERNAME**                 | UsuÃ¡rio SASL para autenticaÃ§Ã£o                               | string                                     | â€”                      | Sim*         | erro*                   |
| **KAFKA_PASSWORD**                 | Senha SASL para autenticaÃ§Ã£o                                 | string                                     | â€”                      | Sim*         | erro*                   |
| **KAFKA_SASL_MECHANISM**           | Mecanismo SASL                                               | PLAIN, SCRAM-SHA-256, SCRAM-SHA-512, etc   | PLAIN                  | NÃ£o          | Usa default             |
| **KAFKA_SECURITY_PROTOCOL**        | Protocolo de seguranÃ§a                                       | PLAINTEXT, SASL_PLAINTEXT, SSL, SASL_SSL   | PLAINTEXT              | NÃ£o          | Usa default             |
| **KAFKA_SCHEMA_REGISTRY_URL**      | URL do Schema Registry                                       | http(s)://host:8081                        | â€”                      | Simâ€ â€         | erro                    |
| **KAFKA_SCHEMA_REGISTRY_USERNAME** | UsuÃ¡rio do Schema Registry                                   | string                                     | â€”                      | Condicionalâ€  | erroâ€                    |
| **KAFKA_SCHEMA_REGISTRY_PASSWORD** | Senha do Schema Registry                                     | string                                     | â€”                      | Condicionalâ€  | erroâ€                    |
| **KAFKA_SCHEMA_REGISTRY_AUTH_SOURCE**| Fonte de credencial do Schema Registry                     | USER_INFO, SASL_INHERIT, NONE              | USER_INFO              | NÃ£o          | Usa default             |
| **KAFKA_TIMEOUT**                  | Timeout de requisiÃ§Ã£o (ms)                                   | inteiro > 0                                | 5000                   | NÃ£o          | Usa default             |
| **KAFKA_PRODUCER_PRIORITY**        | Prioridade do producer                                       | ORDER, BALANCED, HIGH_PERFORMANCE          | ORDER                  | NÃ£o          | Usa default             |
| **KAFKA_CONSUMER_PRIORITY**        | Prioridade do consumer                                       | ORDER, BALANCED, HIGH_PERFORMANCE, RISKY   | ORDER                  | NÃ£o          | Usa default             |
| **KAFKA_AUTO_OFFSET_RESET**        | Offset inicial                                               | EARLIEST, LATEST, BEGINNING, END, etc      | LATEST                 | NÃ£o          | Usa default             |

> \* ObrigatÃ³rio apenas se o protocolo SASL exigir autenticaÃ§Ã£o (ex: PLAIN, SCRAM, etc). Para protocolos sem autenticaÃ§Ã£o (plaintext), essas variÃ¡veis sÃ£o ignoradas.
>
> â€  A obrigatoriedade das credenciais do Schema Registry segue estas regras:
> - Se KAFKA_SCHEMA_REGISTRY_AUTH_SOURCE="USER_INFO" (valor padrÃ£o), entÃ£o KAFKA_SCHEMA_REGISTRY_USERNAME e KAFKA_SCHEMA_REGISTRY_PASSWORD sÃ£o obrigatÃ³rios
> - Se KAFKA_SCHEMA_REGISTRY_AUTH_SOURCE="SASL_INHERIT", as credenciais SASL do Kafka (KAFKA_USERNAME e KAFKA_PASSWORD) serÃ£o utilizadas, e as credenciais especÃ­ficas do Schema Registry sÃ£o ignoradas
> - Se o Schema Registry nÃ£o requerer autenticaÃ§Ã£o, use KAFKA_SCHEMA_REGISTRY_AUTH_SOURCE="" (string vazia)
> - Se KAFKA_SCHEMA_REGISTRY_USERNAME e KAFKA_SCHEMA_REGISTRY_PASSWORD forem informados sem especificar KAFKA_SCHEMA_REGISTRY_AUTH_SOURCE, o valor "USER_INFO" serÃ¡ assumido por padrÃ£o
>
> â€ â€  **ObrigatÃ³rio apenas para serializaÃ§Ã£o Avro, Protobuf e JSON Schema.** Para JSON puro (`JsonSerialization`/`JsonDeserialization`), nÃ£o Ã© necessÃ¡rio configurar o Schema Registry.

> **ğŸŸ¢ DICA DE USO: Preenchimento FlexÃ­vel e Robusto!**
>
> A biblioteca agora inclui **normalizaÃ§Ã£o automÃ¡tica de parÃ¢metros**, permitindo que vocÃª preencha as variÃ¡veis de ambiente em **maiÃºsculas**, **minÃºsculas** ou **misturando** (ex: `ORDER`, `order`, `Order`).
> A biblioteca faz o mapeamento automaticamente para o valor esperado pelo Kafka, tornando a configuraÃ§Ã£o muito mais amigÃ¡vel e Ã  prova de erros de digitaÃ§Ã£o/capitalizaÃ§Ã£o.
>
> **Exemplos prÃ¡ticos de preenchimento:**
>
> - Prioridade do Producer/Consumer:
>   - `KAFKA_PRODUCER_PRIORITY=ORDER`
>   - `KAFKA_PRODUCER_PRIORITY=order`
>   - `KAFKA_PRODUCER_PRIORITY=Order`
>   - `KAFKA_CONSUMER_PRIORITY=HIGH_PERFORMANCE`
>   - `KAFKA_CONSUMER_PRIORITY=high_performance`
>   - `KAFKA_CONSUMER_PRIORITY=High_Performance`
>
> - Protocolo de SeguranÃ§a:
>   - `KAFKA_SECURITY_PROTOCOL=PLAINTEXT`
>   - `KAFKA_SECURITY_PROTOCOL=plaintext`
>   - `KAFKA_SECURITY_PROTOCOL=Plaintext`
>
> - Mecanismo SASL:
>   - `KAFKA_SASL_MECHANISM=PLAIN`
>   - `KAFKA_SASL_MECHANISM=plain`
>   - `KAFKA_SASL_MECHANISM=Plain`
>
> - Offset:
>   - `KAFKA_AUTO_OFFSET_RESET=EARLIEST`
>   - `KAFKA_AUTO_OFFSET_RESET=earliest`
>   - `KAFKA_AUTO_OFFSET_RESET=Earliest`
>
> **NÃ£o importa a capitalizaÃ§Ã£o!**
> 
> A nova implementaÃ§Ã£o garante a normalizaÃ§Ã£o completa dos valores, tornando a configuraÃ§Ã£o Ã  prova de erros e permitindo maior flexibilidade na integraÃ§Ã£o com diferentes sistemas de configuraÃ§Ã£o e ambientes.

### Detalhes e ObservaÃ§Ãµes
- **ObrigatÃ³rios**: KAFKA_BROKERS, KAFKA_GROUPID, e, dependendo do modo de serializaÃ§Ã£o, KAFKA_SCHEMA_REGISTRY_URL e credenciais do Schema Registry.
- **Para JSON puro** (`JsonSerialization`/`JsonDeserialization`):
  - **NÃƒO** Ã© necessÃ¡rio configurar o Schema Registry nem suas credenciais.
- **Para Avro, Protobuf e JSON Schema**:
  - O Schema Registry e suas credenciais podem ser obrigatÃ³rios conforme explicado acima.
- **Erros**: Se uma variÃ¡vel obrigatÃ³ria estiver ausente, a inicializaÃ§Ã£o retorna um erro com mensagem descritiva.
- **Defaults**: VariÃ¡veis nÃ£o obrigatÃ³rias assumem valores padrÃ£o seguros para facilitar o uso em ambientes de desenvolvimento.
- **Valores InvÃ¡lidos**: Se um valor invÃ¡lido for informado, o sistema tenta usar o default ou retorna erro se nÃ£o for possÃ­vel.
- **Exemplo de configuraÃ§Ã£o mÃ­nima para ambiente sem autenticaÃ§Ã£o**:
  ```env
  KAFKA_BROKERS=localhost:9092
  KAFKA_GROUPID=meu-grupo
  KAFKA_SCHEMA_REGISTRY_URL=http://localhost:8081
  KAFKA_SECURITY_PROTOCOL=plaintext
  ```
- **Exemplo de configuraÃ§Ã£o mÃ­nima para JSON puro (sem Schema Registry)**:
  ```env
  KAFKA_BROKERS=localhost:9092
  KAFKA_GROUPID=meu-grupo
  KAFKA_SECURITY_PROTOCOL=plaintext
  ```
- **Exemplo de configuraÃ§Ã£o completa com autenticaÃ§Ã£o**:
  ```env
  KAFKA_BROKERS=broker1:9092,broker2:9092
  KAFKA_GROUPID=app-prod
  KAFKA_SCHEMA_REGISTRY_URL=https://schema-registry:8081
  KAFKA_USERNAME=usuario
  KAFKA_PASSWORD=senha
  KAFKA_SASL_MECHANISM=SCRAM-SHA-256
  KAFKA_SECURITY_PROTOCOL=sasl_ssl
  KAFKA_SCHEMA_REGISTRY_USERNAME=usuario
  KAFKA_SCHEMA_REGISTRY_PASSWORD=senha
  KAFKA_SCHEMA_REGISTRY_AUTH_SOURCE=USER_INFO
  KAFKA_TIMEOUT=10000
  KAFKA_PRODUCER_PRIORITY=ORDER
  KAFKA_CONSUMER_PRIORITY=HIGH_PERFORMANCE
  KAFKA_AUTO_OFFSET_RESET=earliest
  ```

### VerificaÃ§Ã£o AutomÃ¡tica de Valores
A biblioteca realiza verificaÃ§Ã£o automÃ¡tica dos valores informados e faz o mapeamento de valores amigÃ¡veis para os valores esperados pelo Kafka. Por exemplo:

- Para o **KAFKA_AUTO_OFFSET_RESET**, os valores vÃ¡lidos sÃ£o:
  - `EARLIEST`, `BEGINNING`, `SMALLEST` (inÃ­cio do tÃ³pico)
  - `LATEST`, `END`, `LARGEST` (fim do tÃ³pico)
  - `ERROR` (gera erro se nÃ£o houver offset inicial)

- Para o **KAFKA_SASL_MECHANISM**, os valores vÃ¡lidos sÃ£o:
  - `PLAIN`, `SCRAM-SHA-256`, `SCRAM-SHA-512`, `GSSAPI`, `OAUTHBEARER`, `NONE`

- Para o **KAFKA_SECURITY_PROTOCOL**, os valores vÃ¡lidos sÃ£o:
  - `PLAINTEXT`, `SASL_PLAINTEXT`, `SSL`, `SASL_SSL`

- Para o **KAFKA_PRODUCER_PRIORITY** e **KAFKA_CONSUMER_PRIORITY**, os valores vÃ¡lidos sÃ£o:
  - `ORDER`, `BALANCED`, `HIGH_PERFORMANCE`, `RISKY` (consumer)
  - `ORDER`, `BALANCED`, `HIGH_PERFORMANCE` (producer)

> **VocÃª pode usar qualquer capitalizaÃ§Ã£o (ex: `order`, `ORDER`, `Order`). A biblioteca converte automaticamente para o valor correto.**

## Exemplo de Uso

### 1. InicializaÃ§Ã£o do Container de DependÃªncias
```go
import (
    "context"
    "github.com/Dieg657/kafka-toolkit-lib/internal/common/ioc"
    "github.com/Dieg657/kafka-toolkit-lib/internal/common/constants"
)

ctx := context.Background()
iocContainer, err := ioc.NewKafkaIoC(ctx)
if err != nil {
    panic(err)
}
ctx = context.WithValue(ctx, constants.IocKey, iocContainer)
```

### 2. Publicando Mensagens
```go
import (
    "github.com/Dieg657/kafka-toolkit-lib/internal/publisher"
    "github.com/Dieg657/kafka-toolkit-lib/internal/common/message"
    "github.com/Dieg657/kafka-toolkit-lib/internal/common/enums"
    "github.com/google/uuid"
)

type MyPayload struct {
    Field1 string
    Field2 int
}

payload := MyPayload{Field1: "foo", Field2: 42}
correlationId := uuid.New()
msg, _ := message.NewForData(correlationId, payload, map[string][]byte{})
err := publisher.PublishMessage(ctx, "meu-topico", msg, enums.JsonSerialization)
if err != nil {
    panic(err)
}
```

### 3. Consumindo Mensagens
```go
import (
    "github.com/Dieg657/kafka-toolkit-lib/internal/consumer"
    "github.com/Dieg657/kafka-toolkit-lib/internal/common/message"
    "github.com/Dieg657/kafka-toolkit-lib/internal/common/enums"
)

type MyPayload struct {
    Field1 string
    Field2 int
}

handler := func(msg message.Message[MyPayload]) error {
    // Processa a mensagem
    fmt.Println(msg.Data.Field1, msg.Data.Field2)
    return nil
}

err := consumer.ConsumeMessage[MyPayload](ctx, "meu-topico", enums.JsonDeserialization, enums.OnDeserializationIgnoreMessage, handler)
if err != nil {
    panic(err)
}
```

## EstratÃ©gias de DeserializaÃ§Ã£o

A biblioteca oferece estratÃ©gias flexÃ­veis para lidar com falhas de deserializaÃ§Ã£o durante o processamento de mensagens, permitindo diferentes nÃ­veis de tolerÃ¢ncia a falhas conforme a criticidade do seu sistema.

### EstratÃ©gias DisponÃ­veis

#### `OnDeserializationFailedStopHost`
**Comportamento**: Para completamente o consumer ao encontrar erro de deserializaÃ§Ã£o.

**CaracterÃ­sticas**:
- Mais restritivo e seguro para ambientes crÃ­ticos
- Garante que nenhuma mensagem malformada seja ignorada
- Requer intervenÃ§Ã£o manual para resolver o problema

**Uso recomendado**:
- Ambientes de produÃ§Ã£o crÃ­ticos onde dados corrompidos sÃ£o inaceitÃ¡veis
- Sistemas que requerem processamento garantido de todas as mensagens
- CenÃ¡rios onde Ã© preferÃ­vel parar o sistema a processar dados invÃ¡lidos

**Exemplo**:
```go
err := consumer.ConsumeMessage(ctx, "meu-topico", 
    enums.JsonDeserialization, 
    enums.OnDeserializationFailedStopHost, // Para ao encontrar erro
    handler)
```

#### `OnDeserializationIgnoreMessage`
**Comportamento**: Ignora a mensagem que falhou na deserializaÃ§Ã£o e continua processando.

**CaracterÃ­sticas**:
- Mais tolerante e resiliente a falhas
- Permite que o sistema continue funcionando mesmo com mensagens malformadas
- Requer logging adequado para rastrear mensagens ignoradas

**Uso recomendado**:
- Ambientes onde alta disponibilidade Ã© mais importante que processamento garantido
- Sistemas que podem tolerar perda ocasional de mensagens malformadas
- CenÃ¡rios de desenvolvimento e teste
- Processamento em batch onde algumas falhas sÃ£o aceitÃ¡veis

**Exemplo**:
```go
err := consumer.ConsumeMessage(ctx, "meu-topico", 
    enums.JsonDeserialization, 
    enums.OnDeserializationIgnoreMessage, // Ignora erros e continua
    handler)
```

### Quando Usar Cada EstratÃ©gia

| CenÃ¡rio | EstratÃ©gia Recomendada | Justificativa |
|---------|------------------------|---------------|
| **Sistema Financeiro** | `OnDeserializationFailedStopHost` | Dados corrompidos podem causar inconsistÃªncias crÃ­ticas |
| **Analytics/Logs** | `OnDeserializationIgnoreMessage` | Volume alto, algumas perdas sÃ£o aceitÃ¡veis |
| **E-commerce (Carrinho)** | `OnDeserializationFailedStopHost` | TransaÃ§Ãµes requerem integridade completa |
| **MÃ©tricas/Monitoramento** | `OnDeserializationIgnoreMessage` | Disponibilidade Ã© mais importante que precisÃ£o absoluta |
| **Ambiente de Desenvolvimento** | `OnDeserializationIgnoreMessage` | Facilita testes e nÃ£o interrompe desenvolvimento |
| **Compliance/Auditoria** | `OnDeserializationFailedStopHost` | RegulamentaÃ§Ãµes exigem processamento completo |

### Melhores PrÃ¡ticas

1. **Logging**: Sempre implemente logging adequado para rastrear mensagens ignoradas
2. **Monitoramento**: Configure alertas para falhas de deserializaÃ§Ã£o frequentes
3. **Ambiente**: Use estratÃ©gias mais restritivas em produÃ§Ã£o
4. **Schema Evolution**: Planeje evoluÃ§Ã£o de schemas para minimizar incompatibilidades
5. **Testes**: Teste ambas as estratÃ©gias em ambiente de desenvolvimento

## Formatos Suportados

### SerializaÃ§Ã£o/DeserializaÃ§Ã£o
- **Json**
  - enums.JsonSerialization / enums.JsonDeserialization
  - **JSON puro, sem Schema Registry**.
  - Dados sÃ£o convertidos para JSON sem validaÃ§Ã£o de schema.
  - **Vantagens**: Facilidade de uso, flexibilidade, legibilidade humana.
  - **Desvantagens**: Sem validaÃ§Ã£o estrutural, maior tamanho de payload, sem controle de schema.
  - **Recomendado para**: IntegraÃ§Ã£o simples, sistemas legados, ambientes de desenvolvimento, ou quando flexibilidade Ã© mais importante que validaÃ§Ã£o.
  - Exemplo:
    ```go
    enums.JsonSerialization // para publicar
    enums.JsonDeserialization // para consumir
    ```
- **JSON Schema**
  - enums.JsonSchemaSerialization / enums.JsonSchemaDeserialization
  - Dados JSON validados contra um schema JSON definido e registrado.
  - **Vantagens**: ValidaÃ§Ã£o estrutural, legibilidade humana, evoluÃ§Ã£o controlada.
  - **Desvantagens**: Tamanho maior que formatos binÃ¡rios, performance moderada.
  - **Requer**: Schema Registry configurado.
  - **Recomendado para**: APIs REST, integraÃ§Ãµes web, quando Ã© necessÃ¡rio equilÃ­brio entre legibilidade e validaÃ§Ã£o de schema.
  - Exemplo:
    ```go
    enums.JsonSchemaSerialization // para publicar
    enums.JsonSchemaDeserialization // para consumir
    ```
- **Avro**
  - enums.AvroSerialization / enums.AvroDeserialization
  - Formato binÃ¡rio compacto com schemas definidos, Ã³timo desempenho e economia de espaÃ§o.
  - **Vantagens**: Alta compactaÃ§Ã£o, evoluÃ§Ã£o de schema retrocompatÃ­vel, desempenho excelente.
  - **Desvantagens**: NÃ£o Ã© legÃ­vel por humanos, requer ferramentas especÃ­ficas para visualizaÃ§Ã£o.
  - **Requer**: Schema Registry configurado.
  - **Recomendado para**: Alto volume de dados, sistemas de processamento de dados, analytics, quando eficiÃªncia de armazenamento Ã© crÃ­tica.
  - Exemplo:
    ```go
    enums.AvroSerialization // para publicar
    enums.AvroDeserialization // para consumir
    ```
- **Protobuf**
  - enums.ProtobufSerialization / enums.ProtobufDeserialization
  - Formato binÃ¡rio compacto e eficiente baseado em schemas (.proto).
  - **Vantagens**: Extremamente rÃ¡pido, tamanho compacto, forte tipagem, retrocompatibilidade, suporte multi-linguagem.
  - **Desvantagens**: Requer ferramentas especÃ­ficas, curva de aprendizado inicial.
  - **Requer**: Schema Registry configurado.
  - **Recomendado para**: Sistemas de alta performance, comunicaÃ§Ã£o entre serviÃ§os, microservices, aplicaÃ§Ãµes sensÃ­veis Ã  latÃªncia.
  - Exemplo:
    ```go
    enums.ProtobufSerialization // para publicar
    enums.ProtobufDeserialization // para consumir
    ```

## Adaptador Protobuf

### Problemas comuns com Protobuf em Go e como a biblioteca resolve para vocÃª

Ao integrar Protobuf com Kafka em Go, muitos desenvolvedores enfrentam problemas como:

- **Incompatibilidade entre implementaÃ§Ãµes de Protobuf**: O ecossistema Go possui duas principais implementaÃ§Ãµes (`github.com/golang/protobuf` e `google.golang.org/protobuf`), que nÃ£o sÃ£o 100% compatÃ­veis entre si. Isso pode gerar erros difÃ­ceis de diagnosticar.
- **Mensagens de erro confusas**: Ã‰ comum encontrar erros como:
  - `serialization target must be a protobuf message`
  - `cannot use *MyProto as type proto.Message`
- **Necessidade de adaptaÃ§Ã£o manual**: Em outras bibliotecas, o desenvolvedor precisa adaptar manualmente as mensagens ou converter entre tipos, o que gera cÃ³digo extra, manutenÃ§Ã£o difÃ­cil e risco de bugs sutis.

#### Como a Kafka Toolkit Lib resolve para vocÃª

- **AdaptaÃ§Ã£o automÃ¡tica**: A biblioteca detecta automaticamente qual implementaÃ§Ã£o de Protobuf vocÃª estÃ¡ usando e faz toda a ponte necessÃ¡ria, sem exigir nenhuma configuraÃ§Ã£o extra do usuÃ¡rio.
- **TransparÃªncia total**: VocÃª pode usar suas structs Protobuf normalmente, sem se preocupar com detalhes de compatibilidade.
- **Sem cÃ³digo extra**: NÃ£o Ã© necessÃ¡rio criar adaptadores, wrappers ou conversÃµes manuais.
- **Erros resolvidos**: Aqueles erros tÃ­picos de incompatibilidade simplesmente nÃ£o acontecem aqui.

> **Resumo:**
> Basta usar suas mensagens Protobuf normalmente.

### Funcionamento AutomÃ¡tico
Na maioria dos casos, o adaptador funcionarÃ¡ automaticamente sem configuraÃ§Ã£o adicional:

- Detecta automaticamente tipos protobuf usando reflexÃ£o e heurÃ­sticas
- Realiza cÃ³pias de campos entre diferentes implementaÃ§Ãµes
- MantÃ©m cache para otimizar o desempenho

### Exemplo de Uso com Protobuf
```go
import (
    "github.com/Dieg657/kafka-toolkit-lib/internal/publisher"
    "github.com/Dieg657/kafka-toolkit-lib/internal/common/message"
    "github.com/Dieg657/kafka-toolkit-lib/internal/common/enums"
    "github.com/google/uuid"
    pb "seu/pacote/protobuf"
)

// Publicando
payload := &pb.MeuProtobuf{
    Campo1: "teste",
    Campo2: 123,
}
correlationId := uuid.New()
msg, _ := message.NewForData(correlationId, payload, nil)
err := publisher.PublishMessage(ctx, "meu-topico", msg, enums.ProtobufSerialization)

// Consumindo
handler := func(msg message.Message[*pb.MeuProtobuf]) error {
    fmt.Printf("Mensagem recebida: %+v\n", msg.Data)
    return nil
}
err := consumer.ConsumeMessage(ctx, "meu-topico", enums.ProtobufDeserialization, enums.OnDeserializationIgnoreMessage, handler)
```

### Prioridades Producer

> **âš ï¸ Nota sobre Valores Default:**
> O valor padrÃ£o para tanto `KAFKA_PRODUCER_PRIORITY` quanto `KAFKA_CONSUMER_PRIORITY` Ã© **ORDER**. 
> Isto prioriza seguranÃ§a e consistÃªncia por padrÃ£o, garantindo ordem de entrega e processamento.
> Para aplicaÃ§Ãµes que precisam de mais performance, configure explicitamente como `BALANCED` ou `HIGH_PERFORMANCE`.

- **ORDER** (padrÃ£o)
  - Garante ordem de entrega e idempotÃªncia.
  - Uso: sistemas financeiros, logs ordenados, eventos crÃ­ticos.
  - **ConfiguraÃ§Ã£o automÃ¡tica da biblioteca:**
    ```yaml
    acks: all
    enable.idempotence: true
    max.in.flight.requests.per.connection: 1
    retries: 5
    linger.ms: 0
    batch.num.messages: 1000
    compression.type: snappy
    message.timeout.ms: 120000
    request.timeout.ms: 30000
    queue.buffering.max.messages: 100000
    queue.buffering.max.kbytes: 1048576
    retry.backoff.ms: 100
    queue.buffering.max.ms: 0
    ```
  - **O que cada parÃ¢metro faz:**
    - `acks: all` â€” Garante que todas as rÃ©plicas confirmem a mensagem antes de considerar entregue (mÃ¡xima confiabilidade).
    - `enable.idempotence: true` â€” Evita duplicidade de mensagens mesmo em falhas de rede.
    - `max.in.flight.requests.per.connection: 1` â€” Garante ordem absoluta das mensagens.
    - `retries: 5` â€” Tenta reenviar mensagens em caso de falha.
    - `linger.ms: 0` â€” NÃ£o espera para formar lotes, priorizando baixa latÃªncia.
    - `batch.num.messages: 1000` â€” Limita o tamanho dos lotes para controle de memÃ³ria.
    - `compression.type: snappy` â€” CompressÃ£o eficiente para reduzir uso de rede.
    - `message.timeout.ms: 120000` â€” Tempo mÃ¡ximo para tentar entregar uma mensagem.
    - `request.timeout.ms: 30000` â€” Timeout para requisiÃ§Ãµes ao broker.
    - `queue.buffering.max.messages`/`max.kbytes` â€” Controlam o buffer local do produtor.
    - `retry.backoff.ms: 100` â€” Tempo de espera entre tentativas de reenvio.
    - `queue.buffering.max.ms: 0` â€” NÃ£o atrasa entregas para otimizar lotes.
  - **Exemplo:**
    ```env
    KAFKA_PRODUCER_PRIORITY=ORDER
    ```
  - **Quando escolher:**
    - Processos que nÃ£o podem tolerar duplicidade ou reordenaÃ§Ã£o (ex: dÃ©bito em conta, emissÃ£o de nota fiscal).
    - Workflows que dependem de causalidade estrita.

- **BALANCED**
  - EquilÃ­brio entre performance e consistÃªncia.
  - **ConfiguraÃ§Ã£o automÃ¡tica da biblioteca:**
    ```yaml
    acks: all
    enable.idempotence: true
    max.in.flight.requests.per.connection: 5
    retries: 3
    linger.ms: 5
    batch.num.messages: 10000
    compression.type: lz4
    message.timeout.ms: 120000
    request.timeout.ms: 30000
    queue.buffering.max.messages: 200000
    queue.buffering.max.kbytes: 2097152
    retry.backoff.ms: 100
    queue.buffering.max.ms: 5
    ```
  - **O que cada parÃ¢metro faz:**
    - `acks: all` â€” ConfirmaÃ§Ã£o de todas as rÃ©plicas, mas com mais paralelismo.
    - `enable.idempotence: true` â€” SeguranÃ§a contra duplicidade.
    - `max.in.flight.requests.per.connection: 5` â€” Permite paralelismo moderado, balanceando ordem e performance.
    - `retries: 3` â€” TolerÃ¢ncia a falhas.
    - `linger.ms: 5` â€” Pequeno atraso para formar lotes maiores (melhor throughput).
    - `batch.num.messages: 10000` â€” Lotes maiores para eficiÃªncia.
    - `compression.type: lz4` â€” CompressÃ£o rÃ¡pida e eficiente.
    - `message.timeout.ms`/`request.timeout.ms` â€” Controle de tempo de entrega.
    - `queue.buffering.max.messages`/`max.kbytes` â€” Buffers maiores para mais throughput.
    - `retry.backoff.ms: 100` â€” Espera entre tentativas.
    - `queue.buffering.max.ms: 5` â€” Pequeno atraso para otimizar lotes.
  - **Exemplo:**
    ```env
    KAFKA_PRODUCER_PRIORITY=BALANCED
    ```
  - **Quando escolher:**
    - AplicaÃ§Ãµes de uso geral, integraÃ§Ãµes, eventos de negÃ³cio nÃ£o crÃ­ticos.

- **HIGH_PERFORMANCE**
  - MÃ¡ximo throughput, menos garantias de ordem e duplicidade.
  - **ConfiguraÃ§Ã£o automÃ¡tica da biblioteca:**
    ```yaml
    acks: 1
    enable.idempotence: false
    max.in.flight.requests.per.connection: 10
    retries: 1
    linger.ms: 10
    batch.num.messages: 50000
    compression.type: lz4
    message.timeout.ms: 60000
    request.timeout.ms: 20000
    queue.buffering.max.messages: 500000
    queue.buffering.max.kbytes: 4194304
    retry.backoff.ms: 100
    socket.keepalive.enable: true
    queue.buffering.max.ms: 10
    ```
  - **O que cada parÃ¢metro faz:**
    - `acks: 1` â€” ConfirmaÃ§Ã£o sÃ³ do lÃ­der, priorizando velocidade.
    - `enable.idempotence: false` â€” Permite duplicidade para mÃ¡ximo throughput.
    - `max.in.flight.requests.per.connection: 10` â€” AltÃ­ssimo paralelismo.
    - `retries: 1` â€” Pouca tolerÃ¢ncia a falhas.
    - `linger.ms: 10` â€” Espera para formar grandes lotes.
    - `batch.num.messages: 50000` â€” Lotes enormes para eficiÃªncia mÃ¡xima.
    - `compression.type: lz4` â€” CompressÃ£o rÃ¡pida.
    - `message.timeout.ms`/`request.timeout.ms` â€” Tempos menores para agilidade.
    - `queue.buffering.max.messages`/`max.kbytes` â€” Buffers gigantes para throughput.
    - `retry.backoff.ms: 100` â€” Espera curta entre tentativas.
    - `socket.keepalive.enable: true` â€” MantÃ©m conexÃµes ativas.
    - `queue.buffering.max.ms: 10` â€” Pequeno atraso para otimizar lotes.
  - **Exemplo:**
    ```env
    KAFKA_PRODUCER_PRIORITY=HIGH_PERFORMANCE
    ```
  - **Quando escolher:**
    - Coleta de logs, mÃ©tricas, analytics, pipelines de dados massivos.
    - SituaÃ§Ãµes onde performance Ã© mais importante que ordem ou unicidade.
  - **Dica:** Combine com particionamento customizado para priorizar buckets ou classes de mensagens ([Bucket Priority Pattern](https://www.confluent.io/blog/prioritize-messages-in-kafka/)).

### Prioridades Consumer
- **ORDER** (padrÃ£o)
  - Consumo ordenado, maior seguranÃ§a e controle.
  - **ConfiguraÃ§Ã£o automÃ¡tica da biblioteca:**
    ```yaml
    enable.auto.commit: false
    auto.offset.reset: EARLIEST
    isolation.level: read_committed
    max.poll.interval.ms: 300000
    session.timeout.ms: 10000
    heartbeat.interval.ms: 3000
    fetch.min.bytes: 1
    fetch.wait.max.ms: 500
    retry.backoff.ms: 100
    fetch.error.backoff.ms: 500
    max.partition.fetch.bytes: 1048576
    fetch.max.bytes: 5242880
    ```
  - **O que cada parÃ¢metro faz:**
    - `enable.auto.commit: false` â€” Commit manual, mÃ¡xima seguranÃ§a.
    - `auto.offset.reset: EARLIEST` â€” Consome desde o inÃ­cio se nÃ£o houver offset salvo.
    - `isolation.level: read_committed` â€” LÃª apenas mensagens confirmadas.
    - `max.poll.interval.ms: 300000` â€” Tempo mÃ¡ximo para processar lote.
    - `session.timeout.ms: 10000` â€” Timeout de sessÃ£o.
    - `heartbeat.interval.ms: 3000` â€” FrequÃªncia de heartbeat.
    - `fetch.min.bytes: 1` â€” Busca mensagem assim que disponÃ­vel.
    - `fetch.wait.max.ms: 500` â€” Espera mÃ¡xima para buscar.
    - `retry.backoff.ms: 100` â€” Espera entre tentativas.
    - `fetch.error.backoff.ms: 500` â€” Espera apÃ³s erro de fetch.
    - `max.partition.fetch.bytes`/`fetch.max.bytes` â€” Controlam tamanho dos lotes e uso de memÃ³ria.
  - **Exemplo:**
    ```env
    KAFKA_CONSUMER_PRIORITY=ORDER
    ```
  - **Quando escolher:**
    - Processamento de eventos financeiros, pipelines ETL sensÃ­veis Ã  ordem.

- **BALANCED**
  - EquilÃ­brio entre performance e consistÃªncia.
  - **ConfiguraÃ§Ã£o automÃ¡tica da biblioteca:**
    ```yaml
    enable.auto.commit: false
    auto.offset.reset: EARLIEST
    isolation.level: read_committed
    max.poll.interval.ms: 300000
    session.timeout.ms: 30000
    heartbeat.interval.ms: 10000
    fetch.min.bytes: 1024
    fetch.wait.max.ms: 1000
    retry.backoff.ms: 200
    fetch.error.backoff.ms: 500
    max.partition.fetch.bytes: 1048576
    fetch.max.bytes: 10485760
    fetch.message.max.bytes: 262144
    ```
  - **O que cada parÃ¢metro faz:**
    - `enable.auto.commit: false` â€” Commit manual, mais controle.
    - `auto.offset.reset: EARLIEST` â€” Consome desde o inÃ­cio se necessÃ¡rio.
    - `isolation.level: read_committed` â€” LÃª apenas mensagens confirmadas.
    - `max.poll.interval.ms`/`session.timeout.ms` â€” Controlam tempo de processamento e sessÃ£o.
    - `heartbeat.interval.ms` â€” FrequÃªncia de heartbeat.
    - `fetch.min.bytes`/`fetch.wait.max.ms` â€” Controlam batching e latÃªncia.
    - `retry.backoff.ms`/`fetch.error.backoff.ms` â€” ResiliÃªncia a falhas.
    - `max.partition.fetch.bytes`/`fetch.max.bytes`/`fetch.message.max.bytes` â€” Controlam tamanho dos lotes e uso de memÃ³ria.
  - **Exemplo:**
    ```env
    KAFKA_CONSUMER_PRIORITY=BALANCED
    ```
  - **Quando escolher:**
    - Consumo de eventos de negÃ³cio, integraÃ§Ãµes, sistemas de workflow.

- **HIGH_PERFORMANCE**
  - Consumo rÃ¡pido, menos garantias de ordem.
  - **ConfiguraÃ§Ã£o automÃ¡tica da biblioteca:**
    ```yaml
    enable.auto.commit: true
    auto.commit.interval.ms: 5000
    auto.offset.reset: LATEST
    isolation.level: read_uncommitted
    max.poll.interval.ms: 600000
    session.timeout.ms: 60000
    heartbeat.interval.ms: 20000
    fetch.min.bytes: 65536
    fetch.wait.max.ms: 100
    retry.backoff.ms: 50
    fetch.error.backoff.ms: 200
    max.partition.fetch.bytes: 10485760
    fetch.max.bytes: 52428800
    fetch.message.max.bytes: 1048576
    ```
  - **O que cada parÃ¢metro faz:**
    - `enable.auto.commit: true` â€” Commit automÃ¡tico, mais performance.
    - `auto.commit.interval.ms: 5000` â€” Commit frequente.
    - `auto.offset.reset: LATEST` â€” Consome apenas novas mensagens.
    - `isolation.level: read_uncommitted` â€” LÃª todas as mensagens, mesmo nÃ£o confirmadas.
    - `max.poll.interval.ms`/`session.timeout.ms` â€” Tempos maiores para processar grandes lotes.
    - `heartbeat.interval.ms` â€” Heartbeat menos frequente.
    - `fetch.min.bytes`/`fetch.wait.max.ms` â€” Lotes grandes, menor latÃªncia.
    - `retry.backoff.ms`/`fetch.error.backoff.ms` â€” ResiliÃªncia a falhas.
    - `max.partition.fetch.bytes`/`fetch.max.bytes`/`fetch.message.max.bytes` â€” Lotes e buffers grandes para throughput.
  - **Exemplo:**
    ```env
    KAFKA_CONSUMER_PRIORITY=HIGH_PERFORMANCE
    ```
  - **Quando escolher:**
    - Analytics, logs, ingestÃ£o massiva de dados.
    - SituaÃ§Ãµes onde performance Ã© mais importante que ordem ou confiabilidade.
  - **Dica:** Combine com estratÃ©gias de particionamento e assignors customizados para priorizaÃ§Ã£o de buckets ([Bucket Priority Pattern](https://www.confluent.io/blog/prioritize-messages-in-kafka/)).

- **RISKY**
  - MÃ¡ximo throughput, mÃ­nimo de garantias (auto-commit, menos consistÃªncia).
  - **ConfiguraÃ§Ã£o automÃ¡tica da biblioteca:**
    ```yaml
    enable.auto.commit: true
    auto.commit.interval.ms: 1000
    auto.offset.reset: LATEST
    isolation.level: read_uncommitted
    max.poll.interval.ms: 900000
    session.timeout.ms: 120000
    heartbeat.interval.ms: 40000
    fetch.min.bytes: 131072
    fetch.wait.max.ms: 50
    retry.backoff.ms: 10
    fetch.error.backoff.ms: 100
    reconnect.backoff.ms: 10
    max.partition.fetch.bytes: 52428800
    fetch.max.bytes: 104857600
    fetch.message.max.bytes: 4194304
    ```
  - **O que cada parÃ¢metro faz:**
    - `enable.auto.commit: true` â€” Commit automÃ¡tico, mÃ¡xima velocidade.
    - `auto.commit.interval.ms: 1000` â€” Commit muito frequente.
    - `auto.offset.reset: LATEST` â€” Consome apenas novas mensagens.
    - `isolation.level: read_uncommitted` â€” LÃª todas as mensagens.
    - `max.poll.interval.ms`/`session.timeout.ms` â€” Tempos longos para processar grandes lotes.
    - `heartbeat.interval.ms` â€” Heartbeat menos frequente.
    - `fetch.min.bytes`/`fetch.wait.max.ms` â€” Lotes enormes, mÃ­nima latÃªncia.
    - `retry.backoff.ms`/`fetch.error.backoff.ms`/`reconnect.backoff.ms` â€” ResiliÃªncia mÃ­nima, foco em velocidade.
    - `max.partition.fetch.bytes`/`fetch.max.bytes`/`fetch.message.max.bytes` â€” Buffers e lotes gigantes para mÃ¡ximo throughput.
  - **Exemplo:**
    ```env
    KAFKA_CONSUMER_PRIORITY=RISKY
    ```
  - **Quando escolher:**
    - Monitoramento, mÃ©tricas, logs de auditoria nÃ£o crÃ­ticos.
    - Processamento best-effort, onde o volume Ã© mais importante que a precisÃ£o.

> **Dica AvanÃ§ada:**
> Para cenÃ¡rios de priorizaÃ§Ã£o real de mensagens, utilize padrÃµes como custom partitioners e assignors (ex: Bucket Priority Pattern). Isso permite que diferentes consumidores ou buckets recebam fatias especÃ­ficas do throughput, mesmo dentro do mesmo consumer group, otimizando recursos e garantindo SLAs diferenciados. Saiba mais em: [Prioritize Messages in Kafka](https://www.confluent.io/blog/prioritize-messages-in-kafka/)

### Offset
- **EARLIEST**
  - Consome desde o inÃ­cio do tÃ³pico.
  - Inicia o consumo desde a mensagem mais antiga disponÃ­vel no tÃ³pico.
  - Garante que todas as mensagens disponÃ­veis dentro da polÃ­tica de retenÃ§Ã£o sejam processadas.
  - **Recomendado para**: Reprocessamento, bootstrap de dados, ou inicializaÃ§Ã£o de novos consumidores que precisam processar todo o histÃ³rico.
- **LATEST** (padrÃ£o)
  - Consome apenas novas mensagens que chegarem apÃ³s a conexÃ£o do consumidor.
  - Ignora todas as mensagens existentes no tÃ³pico antes da conexÃ£o.
  - **Recomendado para**: A maioria dos casos de uso em produÃ§Ã£o, especialmente para processamento em tempo real onde o histÃ³rico nÃ£o Ã© relevante.
- **BEGINNING**
  - SinÃ´nimo de EARLIEST.
  - Similar a "earliest", mas pode ter comportamento diferente em algumas implementaÃ§Ãµes.
  - **Nota tÃ©cnica**: Consulte a documentaÃ§Ã£o do Kafka para detalhes especÃ­ficos da sua versÃ£o.
- **END**
  - SinÃ´nimo de LATEST.
  - Similar a "latest", mas pode ter comportamento diferente em algumas implementaÃ§Ãµes.
  - **Nota tÃ©cnica**: Consulte a documentaÃ§Ã£o do Kafka para detalhes especÃ­ficos da sua versÃ£o.
- **SMALLEST**
  - Termo legado equivalente a "earliest".
  - Mantido para compatibilidade com versÃµes antigas do Kafka.
  - **Recomendado para**: CÃ³digo legado ou compatibilidade com clientes antigos.
- **LARGEST**
  - Termo legado equivalente a "latest".
  - Mantido para compatibilidade com versÃµes antigas do Kafka.
  - **Recomendado para**: CÃ³digo legado ou compatibilidade com clientes antigos.
- **ERROR**
  - Gera erro se nÃ£o houver offset vÃ¡lido salvo para o consumer group.
  - A aplicaÃ§Ã£o receberÃ¡ um erro e deverÃ¡ tratÃ¡-lo manualmente.
  - **Recomendado para**: Debugging, validaÃ§Ã£o de fluxos, e cenÃ¡rios onde o processamento precisa ser explicitamente controlado.

### Protocolos de SeguranÃ§a
- **PLAINTEXT**
  - Sem criptografia ou autenticaÃ§Ã£o.
  - **ATENÃ‡ÃƒO**: NÃƒO RECOMENDADO para ambientes de produÃ§Ã£o ou qualquer ambiente exposto Ã  rede pÃºblica.
  - **Recomendado apenas para**: Ambientes de desenvolvimento totalmente isolados e testes locais.
- **SASL_PLAINTEXT**
  - Implementa autenticaÃ§Ã£o SASL mas sem criptografia.
  - As credenciais sÃ£o autenticadas, mas as mensagens trafegam em texto claro.
  - **Recomendado apenas para**: Redes internas totalmente isoladas e seguras.
- **SSL**
  - ComunicaÃ§Ã£o criptografada via SSL/TLS.
  - Fornece criptografia do trÃ¡fego, mas sem autenticaÃ§Ã£o SASL.
  - A autenticaÃ§Ã£o pode ser implementada via certificados de cliente.
  - **Recomendado para**: Ambientes de produÃ§Ã£o onde a autenticaÃ§Ã£o Ã© feita por outros meios.
- **SASL_SSL**
  - Combina autenticaÃ§Ã£o SASL e criptografia SSL/TLS.
  - Oferece o mÃ¡ximo de seguranÃ§a com autenticaÃ§Ã£o robusta e trÃ¡fego criptografado.
  - **Recomendado para**: Ambientes de produÃ§Ã£o, dados sensÃ­veis, e comunicaÃ§Ã£o atravÃ©s de redes pÃºblicas.

### SASL Mechanisms
- **PLAIN**
  - UsuÃ¡rio/Senha simples. FÃ¡cil de configurar, menos seguro.
  - **AtenÃ§Ã£o**: Credenciais sÃ£o transmitidas em texto claro. Utilize apenas em conjunto com SSL/TLS.
  - **Recomendado para**: Ambientes de desenvolvimento ou quando a seguranÃ§a Ã© implementada na camada de transporte.
- **SCRAM-SHA-256**
  - AutenticaÃ§Ã£o forte baseada em hash SHA-256.
  - Oferece melhor seguranÃ§a que PLAIN sem transmitir senhas em texto claro.
  - **Recomendado para**: Maioria dos ambientes de produÃ§Ã£o com requisitos moderados de seguranÃ§a.
- **SCRAM-SHA-512**
  - AutenticaÃ§Ã£o forte baseada em hash SHA-512.
  - Oferece seguranÃ§a superior ao SHA-256, mas maior sobrecarga computacional.
  - **Recomendado para**: Ambientes de alta seguranÃ§a e dados sensÃ­veis.
- **GSSAPI**
  - Implementa autenticaÃ§Ã£o Kerberos/GSSAPI.
  - Adequado para ambientes com infraestrutura Kerberos existente.
  - **Recomendado para**: Ambientes corporativos e integraÃ§Ã£o com Active Directory/MIT Kerberos.
- **OAUTHBEARER**
  - Implementa autenticaÃ§Ã£o baseada em OAuth 2.0.
  - Adequado para integraÃ§Ã£o com provedores de identidade externos.
  - **Recomendado para**: Ambientes cloud e sistemas que jÃ¡ utilizam OAuth para autenticaÃ§Ã£o federada.
- **NONE**
  - Sem mecanismo SASL, apenas para conexÃµes sem autenticaÃ§Ã£o.
  - **Recomendado para**: Apenas ambientes isolados, desenvolvimento local e testes.

### Schema Registry Auth Source
- **USER_INFO**
  - Usa usuÃ¡rio/senha informados nas variÃ¡veis de ambiente.
- **SASL_INHERIT**
  - Herda autenticaÃ§Ã£o SASL do Kafka.
- **""** (vazio)
  - Sem autenticaÃ§Ã£o (apenas para Schema Registry aberto).

> **Dica:** Sempre valide as opÃ§Ãµes de configuraÃ§Ã£o conforme o ambiente (dev, staging, prod) e as polÃ­ticas de seguranÃ§a da sua organizaÃ§Ã£o.

## Playground - Teste antes de integrar

A biblioteca inclui um ambiente de playground completo para que vocÃª possa experimentar todas as funcionalidades sem precisar integrar imediatamente ao seu projeto. O playground permite testar a biblioteca em um ambiente local controlado com Kafka, Zookeeper, Schema Registry e Kafka UI.

### Ambientes DisponÃ­veis

O playground oferece duas configuraÃ§Ãµes diferentes:

1. **Ambiente Simples (sem SASL)** - `docker-compose.yaml`
   - Sem autenticaÃ§Ã£o (usa PLAINTEXT)
   - Ideal para testes rÃ¡pidos e demonstraÃ§Ãµes
   - TÃ³picos sÃ£o criados automaticamente

2. **Ambiente com SASL** - `docker-compose.sasl.yaml`
   - Com autenticaÃ§Ã£o SASL/PLAIN
   - Similar a ambientes corporativos/produtivos
   - Demonstra cenÃ¡rios de autenticaÃ§Ã£o

### Exemplos Prontos para Uso

O playground inclui exemplos para todos os formatos de serializaÃ§Ã£o suportados:

- **Avro**: `playground/avro_example/main.go`
- **Protobuf**: `playground/protobuf_example/main.go`
- **JSON Schema**: `playground/json_schema_example/main.go`
- **JSON**: `playground/json_example/main.go`

### Benchmark de ProduÃ§Ã£o

**ğŸ†• NOVIDADE**: A biblioteca agora inclui um benchmark especializado para medir a performance de **produÃ§Ã£o** de mensagens Kafka.

- **LocalizaÃ§Ã£o**: `playground/benchmark/`
- **Foco**: Exclusivamente na performance de producers
- **MÃ©tricas**: Throughput, latÃªncia (mÃ©dia, P95, P99), taxa de sucesso
- **AnÃ¡lise Inteligente**: ClassificaÃ§Ã£o automÃ¡tica de performance
- **RelatÃ³rios**: Detalhados com recomendaÃ§Ãµes de otimizaÃ§Ã£o
- **Estimativas**: ProjeÃ§Ãµes de capacidade por hora/dia

#### Como usar o Benchmark:
```sh
cd playground/benchmark/example
go run main.go
```

#### Exemplo de RelatÃ³rio:
```
ğŸš€ PRODUÃ‡ÃƒO:
   Total de mensagens: 15,642
   Mensagens com sucesso: 15,642 (100.00%)
   Throughput: 521.40 mensagens/segundo
   LatÃªncia mÃ©dia: 2.15 ms

ğŸ“Š ANÃLISE DE PERFORMANCE:
   Taxa de Sucesso: âœ… EXCELENTE (100.00%)
   Throughput: âš ï¸  MÃ‰DIO (521 msg/s)
   LatÃªncia: âœ… BAIXA (2.15 ms)

ğŸ’¡ RECOMENDAÃ‡Ã•ES:
   - Ajuste batch.size (ex: 16384 ou 32768)
   - Configure linger.ms (ex: 5-10ms)

ğŸ“Š ESTIMATIVA DE CAPACIDADE:
   - Por hora: ~1,877,040 mensagens
   - Por dia: ~45,048,960 mensagens
```

#### ConfiguraÃ§Ã£o Personalizada:
```go
config := benchmark.NewDefaultConfig()
config.ProducerWorkers = 8                      // 8 producers
config.Duration = 60 * time.Second              // 1 minuto
config.TopicName = "meu-topico-benchmark"       // TÃ³pico customizado

result := benchmark.RunProducerOnlyBenchmark(ctx, config)
```

> Para documentaÃ§Ã£o completa do benchmark, consulte: `playground/benchmark/README.md`

### Como Utilizar o Playground

#### 1. Clone o repositÃ³rio
```sh
git clone https://github.com/Dieg657/kafka-toolkit-lib.git
cd kafka-toolkit-lib
```

#### 2. Inicie o ambiente Docker
```sh
# Ambiente sem autenticaÃ§Ã£o
docker compose -f playground/docker-compose.yaml up -d

# OU para ambiente com autenticaÃ§Ã£o
docker compose -f playground/docker-compose.sasl.yaml up -d
```

#### 3. Configure as variÃ¡veis de ambiente

Para ambiente sem autenticaÃ§Ã£o:
```sh
# Linux/macOS
export KAFKA_BROKERS=localhost:29093
export KAFKA_GROUPID=my-test-group
export KAFKA_SCHEMA_REGISTRY_URL=http://localhost:8081
export KAFKA_SECURITY_PROTOCOL=plaintext
export KAFKA_SASL_MECHANISM=PLAIN
export KAFKA_SCHEMA_REGISTRY_USERNAME=schema-registry
export KAFKA_SCHEMA_REGISTRY_PASSWORD=schema-registry-password
export KAFKA_SHEMA_REGISTRY_AUTH_SOURCE=""

# Windows (PowerShell)
$env:KAFKA_BROKERS="localhost:29093"
$env:KAFKA_GROUPID="my-test-group"
$env:KAFKA_SCHEMA_REGISTRY_URL="http://localhost:8081"
$env:KAFKA_SECURITY_PROTOCOL="plaintext"
$env:KAFKA_SASL_MECHANISM="PLAIN"
$env:KAFKA_SCHEMA_REGISTRY_USERNAME="schema-registry"
$env:KAFKA_SCHEMA_REGISTRY_PASSWORD="schema-registry-password"
```

#### 4. Execute um dos exemplos
```sh
go run playground/avro_example/main.go
# OU
go run playground/protobuf_example/main.go
# OU
go run playground/json_schema_example/main.go
# OU
go run playground/json_example/main.go
# OU - NOVO BENCHMARK
go run playground/benchmark/example/main.go
```

#### 5. Explore a interface web
O ambiente inclui uma interface web Kafka UI para visualizar tÃ³picos e mensagens:
- Acesse: http://localhost:8080

### BenefÃ­cios do Playground

- **Teste Completo**: Experimente todos os recursos em um ambiente isolado
- **ValidaÃ§Ã£o de Conceitos**: Entenda como a biblioteca funciona antes de integrar
- **Ambiente Realista**: Inclui todas as dependÃªncias (Kafka, Schema Registry)
- **Aprendizado PrÃ¡tico**: Exemplos prontos e funcionais para cada formato
- **AvaliaÃ§Ã£o TÃ©cnica**: Valide se a biblioteca atende Ã s necessidades do seu projeto
- **ğŸ†• Benchmark de Performance**: Teste e otimize a performance de produÃ§Ã£o

> Para mais detalhes e configuraÃ§Ãµes avanÃ§adas, consulte a documentaÃ§Ã£o do playground: `/playground/README.md`

## Estrutura da Mensagem

A biblioteca utiliza uma estrutura genÃ©rica tipada para representar mensagens Kafka:

```go
type Message[TData any] struct {
    CorrelationId uuid.UUID
    Data          TData
    Metadata      map[string][]byte
}
```

### Detalhamento dos Campos

#### CorrelationId (uuid.UUID)
- **Finalidade**: Identificador Ãºnico de correlaÃ§Ã£o que permite rastrear uma mensagem atravÃ©s de diferentes sistemas e componentes
- **ImportÃ¢ncia**: Fundamental para observabilidade, rastreamento de fluxos e depuraÃ§Ã£o em arquiteturas distribuÃ­das
- **GeraÃ§Ã£o**: Normalmente gerado com `uuid.New()` durante a criaÃ§Ã£o da mensagem
- **Uso**: Deve ser propagado entre sistemas, permitindo correlacionar logs, mÃ©tricas e traces
- **Caso de Uso**: Ideal para acompanhar o caminho de uma requisiÃ§Ã£o que passa por mÃºltiplos serviÃ§os

#### Data (TData)
- **Finalidade**: ContÃ©m o payload principal da mensagem com tipo fortemente definido
- **Flexibilidade**: Utiliza genÃ©ricos do Go para garantir tipagem segura sem comprometer flexibilidade
- **Compatibilidade**: Suporta qualquer tipo Go que possa ser serializado (struct, map, slice, tipos primitivos)
- **Vantagens**: 
  - Evita type assertions e conversÃµes manuais
  - Garante seguranÃ§a de tipos em tempo de compilaÃ§Ã£o
  - Melhora legibilidade e manutenÃ§Ã£o do cÃ³digo
- **Caso de Uso**: TransferÃªncia de dados estruturados entre produtores e consumidores

#### Metadata (map[string][]byte)
- **Finalidade**: Armazenar informaÃ§Ãµes adicionais que nÃ£o pertencem ao payload principal, mas sÃ£o relevantes para processamento, rastreamento ou contexto
- **ConteÃºdo TÃ­pico**:
  - Timestamps de processamento
  - Identificadores de origem/destino
  - InformaÃ§Ãµes de roteamento
  - Flags de controle
  - Dados de instrumentaÃ§Ã£o
  - VersÃµes de schema/API
- **Natureza**: Opcional, pode ser nil ou vazio quando nÃ£o necessÃ¡rio
- **Flexibilidade**: Campos em bytes permitem qualquer tipo de dado serializado, inclusive binÃ¡rios
- **Caso de Uso**: Passar headers HTTP originais, dados de autenticaÃ§Ã£o, ou informaÃ§Ãµes de rastreamento

### Exemplos de Uso da Estrutura

#### Exemplo BÃ¡sico
```go
// Criando uma mensagem simples
payload := MyStruct{Field1: "valor", Field2: 42}
correlationId := uuid.New()
msg, err := message.NewForData(correlationId, payload, nil)
```

#### Utilizando Metadados
```go
// Criando uma mensagem com metadados
payload := MyStruct{Field1: "valor", Field2: 42}
metadata := map[string][]byte{
    "source":      []byte("api-gateway"),
    "request-id":  []byte("req-123456"),
    "timestamp":   []byte(time.Now().Format(time.RFC3339)),
    "trace-token": []byte("trace-abc-xyz"),
}

correlationId := uuid.New()
msg, err := message.NewForData(correlationId, payload, metadata)
```

#### Acessando Metadados no Consumidor
```go
handler := func(msg message.Message[MyStruct]) error {
    // Acessando o payload tipado
    fmt.Println("Dados:", msg.Data.Field1, msg.Data.Field2)
    
    // Acessando metadados
    if source, ok := msg.Metadata["source"]; ok {
        fmt.Println("Origem:", string(source))
    }
    
    if traceToken, ok := msg.Metadata["trace-token"]; ok {
        // Usar o token para correlacionar com sistemas de tracing
        fmt.Println("Token de trace:", string(traceToken))
    }
    
    return nil
}
```

### Melhores PrÃ¡ticas

1. **CorrelaÃ§Ã£o**: Sempre reutilize o CorrelationId ao repassar mensagens para outros sistemas
2. **ConsistÃªncia**: Defina padrÃµes de nomenclatura para chaves de metadados em toda sua organizaÃ§Ã£o
3. **Tamanho**: Mantenha metadados pequenos e focados em informaÃ§Ãµes essenciais
4. **EvoluÃ§Ã£o**: Projete sua estrutura de Data pensando em evoluÃ§Ã£o e versionamento
5. **SeguranÃ§a**: NÃ£o armazene informaÃ§Ãµes sensÃ­veis em metadados, a menos que estejam criptografadas

## Compatibilidade

A biblioteca foi testada e Ã© compatÃ­vel com as seguintes versÃµes:

- Apache Kafka: 2.x, 3.x
- Confluent Schema Registry: 5.x, 6.x, 7.x
- Confluent Kafka Go Client: v2.x
- Go: 1.18+

Para garantir a melhor experiÃªncia, recomendamos:
- Confluent Platform 7.x ou superior
- Go 1.19 ou superior
- Schema Registry com suporte a mÃºltiplos formatos de serializaÃ§Ã£o (Avro, Protobuf, JSON Schema)

### ConfiguraÃ§Ã£o do Schema Registry

> **AtenÃ§Ã£o:**
> Se vocÃª informar `KAFKA_SCHEMA_REGISTRY_USERNAME` e `KAFKA_SCHEMA_REGISTRY_PASSWORD` mas **nÃ£o definir explicitamente** o valor de `KAFKA_SCHEMA_REGISTRY_AUTH_SOURCE`, a biblioteca irÃ¡ **assumir automaticamente** o valor `USER_INFO` como default.
>
> Isso garante que as credenciais fornecidas sejam usadas corretamente para autenticaÃ§Ã£o bÃ¡sica no Schema Registry, sem necessidade de configuraÃ§Ã£o extra.
>
> **Exemplo prÃ¡tico:**
> ```env
> KAFKA_SCHEMA_REGISTRY_URL=http://localhost:8081
> KAFKA_SCHEMA_REGISTRY_USERNAME=meu-usuario
> KAFKA_SCHEMA_REGISTRY_PASSWORD=minha-senha
> # KAFKA_SCHEMA_REGISTRY_AUTH_SOURCE nÃ£o informado
> # A biblioteca assume USER_INFO automaticamente
> ```

#### Valores possÃ­veis para `KAFKA_SCHEMA_REGISTRY_AUTH_SOURCE` e seus efeitos

- **`USER_INFO`** (default se username/senha forem informados)
  - **O que faz:** Usa as credenciais fornecidas em `KAFKA_SCHEMA_REGISTRY_USERNAME` e `KAFKA_SCHEMA_REGISTRY_PASSWORD` para autenticaÃ§Ã£o bÃ¡sica no Schema Registry.
  - **Quando usar:** Quando o Schema Registry tem usuÃ¡rio/senha prÃ³prios, diferentes do Kafka.
  - **Exemplo:**
    ```env
    KAFKA_SCHEMA_REGISTRY_AUTH_SOURCE=USER_INFO
    KAFKA_SCHEMA_REGISTRY_USERNAME=usuario
    KAFKA_SCHEMA_REGISTRY_PASSWORD=senha
    ```

- **`SASL_INHERIT`**
  - **O que faz:** Herda as credenciais do Kafka (`KAFKA_USERNAME` e `KAFKA_PASSWORD`) para autenticaÃ§Ã£o no Schema Registry.
  - **Quando usar:** Quando o Schema Registry compartilha as mesmas credenciais do cluster Kafka (ambientes corporativos, SSO, etc).
  - **Exemplo:**
    ```env
    KAFKA_SCHEMA_REGISTRY_AUTH_SOURCE=SASL_INHERIT
    KAFKA_USERNAME=usuario
    KAFKA_PASSWORD=senha
    # NÃ£o precisa informar KAFKA_SCHEMA_REGISTRY_USERNAME/KAFKA_SCHEMA_REGISTRY_PASSWORD
    ```

- **`""`** (string vazia)
  - **O que faz:** NÃ£o utiliza autenticaÃ§Ã£o para o Schema Registry (acesso aberto).
  - **Quando usar:** Quando o Schema Registry estÃ¡ aberto/publicamente acessÃ­vel e nÃ£o exige autenticaÃ§Ã£o.
  - **Exemplo:**
    ```env
    KAFKA_SCHEMA_REGISTRY_AUTH_SOURCE=""
    # NÃ£o precisa informar usuÃ¡rio/senha
    ```

> **Resumo:**
> - Informe `USER_INFO` para usar credenciais especÃ­ficas do Schema Registry.
> - Use `SASL_INHERIT` para herdar as credenciais do Kafka.
> - Use `""` (vazio) para Schema Registry sem autenticaÃ§Ã£o.

## Exemplo de Uso

## Thread-safety e Singleton: Publisher e Consumer

> **ğŸš¦ InformaÃ§Ã£o CrÃ­tica: Publisher e Consumer sÃ£o Singleton e Thread-safe!**
>
> A biblioteca garante que tanto o **Publisher** quanto o **Consumer** sÃ£o:
> - **Singleton por tipo de dado** (e por tÃ³pico, quando aplicÃ¡vel)
> - **Thread-safe**: podem ser usados em mÃºltiplas goroutines sem risco de mÃºltiplas instÃ¢ncias ou condiÃ§Ãµes de corrida
>
> Isso Ã© possÃ­vel graÃ§as ao uso de `sync.Map` e do padrÃ£o `LoadOrStore`, que garantem que:
> - SÃ³ existe **um Publisher por tipo** (`TData`) em toda a aplicaÃ§Ã£o
> - SÃ³ existe **um Producer por tipo+tÃ³pico**
> - SÃ³ existe **um Consumer por tipo+tÃ³pico**
> - SÃ³ existe **um engine consumer por tipo+tÃ³pico**
>
> **Por que isso Ã© importante?**
> - Evita mÃºltiplas conexÃµes desnecessÃ¡rias com o Kafka
> - Garante uso eficiente de recursos
> - Elimina bugs de concorrÃªncia e race conditions
> - Permite mÃ¡xima performance e escalabilidade
> - Facilita a integraÃ§Ã£o em aplicaÃ§Ãµes de alta concorrÃªncia (microserviÃ§os, workers, etc)
>
> **Exemplo prÃ¡tico:**
>
> ```go
> // Pode usar em quantas goroutines quiser, sempre serÃ¡ singleton e thread-safe!
> for i := 0; i < 100; i++ {
>     go func() {
>         publisher.PublishMessage(ctx, "meu-topico", msg, enums.JsonSerialization)
>         consumer.ConsumeMessage(ctx, "meu-topico", enums.JsonDeserialization, handler)
>     }()
> }
> ```
>
> **Diferencial:**
> - Esse design robusto Ã© um dos grandes diferenciais da biblioteca e pode ser decisivo na escolha para projetos que exigem alta confiabilidade e performance.

## Testes de Singleton e ConcorrÃªncia

A biblioteca inclui testes automatizados que garantem o padrÃ£o singleton mesmo sob concorrÃªncia intensa. Os testes lanÃ§am mÃºltiplas goroutines que tentam obter o IoC container, o producer e o consumer simultaneamente, e validam que **todas as instÃ¢ncias retornadas sÃ£o idÃªnticas**.

### Como rodar os testes

Para rodar todos os testes do projeto:
```sh
go test ./...
```

Para rodar apenas os testes do IoC container:
```sh
go test ./internal/common/ioc
```

Para ver o output detalhado:
```sh
go test -v ./internal/common/ioc
```

> Se algum teste de singleton falhar, isso indica que mÃºltiplas instÃ¢ncias estÃ£o sendo criadas, o que nÃ£o deve acontecer.

## ğŸ†• Ãšltimas AtualizaÃ§Ãµes

### Benchmark de ProduÃ§Ã£o Kafka
- **LocalizaÃ§Ã£o**: `playground/benchmark/`
- **Funcionalidade**: Benchmark especializado para medir performance de producers
- **MÃ©tricas**: Throughput, latÃªncia (mÃ©dia, P95, P99), taxa de sucesso
- **AnÃ¡lise Inteligente**: ClassificaÃ§Ã£o automÃ¡tica de performance com recomendaÃ§Ãµes
- **Estimativas**: ProjeÃ§Ãµes de capacidade por hora/dia
- **RelatÃ³rios**: Detalhados com sugestÃµes de otimizaÃ§Ã£o especÃ­ficas

### EstratÃ©gias de DeserializaÃ§Ã£o
- **Funcionalidade**: Controle flexÃ­vel de comportamento em falhas de deserializaÃ§Ã£o
- **EstratÃ©gias DisponÃ­veis**:
  - `OnDeserializationFailedStopHost`: Para o sistema em caso de erro
  - `OnDeserializationIgnoreMessage`: Ignora mensagens com erro e continua
- **Uso**: Permite configurar tolerÃ¢ncia a falhas conforme criticidade do sistema
- **DocumentaÃ§Ã£o**: Guia completo com cenÃ¡rios de uso e melhores prÃ¡ticas

### Melhorias na API
- **Consumer**: Assinatura atualizada para incluir estratÃ©gia de deserializaÃ§Ã£o obrigatÃ³ria
- **DocumentaÃ§Ã£o**: Enums completamente documentados seguindo padrÃµes da biblioteca
- **Exemplos**: Todos os exemplos do playground atualizados com as novas funcionalidades

### Como Atualizar

Para usar as novas funcionalidades, atualize suas chamadas de `ConsumeMessage`:

**Antes:**
```go
err := consumer.ConsumeMessage(ctx, "topico", enums.JsonDeserialization, handler)
```

**Agora:**
```go
err := consumer.ConsumeMessage(ctx, "topico", enums.JsonDeserialization, enums.OnDeserializationIgnoreMessage, handler)
```

> **Nota**: A estratÃ©gia de deserializaÃ§Ã£o agora Ã© **obrigatÃ³ria** para maior controle e seguranÃ§a.